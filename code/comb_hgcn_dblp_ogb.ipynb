{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:07.800140Z",
          "iopub.status.busy": "2021-11-03T06:00:07.799891Z",
          "iopub.status.idle": "2021-11-03T06:00:08.509581Z",
          "shell.execute_reply": "2021-11-03T06:00:08.508770Z",
          "shell.execute_reply.started": "2021-11-03T06:00:07.800068Z"
        },
        "id": "Y2JJQt0p13mS",
        "outputId": "9cf25e61-26ea-4bd6-abcd-9aa8959cee30",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "output_type": "error",
          "traceback": [
            "Error: Session cannot generate requests",
            "at w.executeCodeCell (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
            "at w.execute (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
            "at w.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
            "at runMicrotasks (<anonymous>)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at async t.CellExecutionQueue.executeQueuedCells (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
            "at async t.CellExecutionQueue.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  !nvidia-smi\n",
        "\n",
        "except:\n",
        "  IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0mmf4TeY41d"
      },
      "source": [
        "مقایسه بین تعداد نورونهای لایه پنهان متفاوت در روابط مختلف\n",
        "مقایسه روابط مختلف که کدام روابط نتیجه بهتری دارند\n",
        "کدام زمان کمتری دارند\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:08.512072Z",
          "iopub.status.busy": "2021-11-03T06:00:08.511758Z",
          "iopub.status.idle": "2021-11-03T06:00:08.522343Z",
          "shell.execute_reply": "2021-11-03T06:00:08.521542Z",
          "shell.execute_reply.started": "2021-11-03T06:00:08.512037Z"
        },
        "id": "wp0E9mvTXDBl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "#    Copyright (C) 2021-2029 by\n",
        "#    Mahmood Amintoosi <m.amintoosi@gmail.com>\n",
        "#    All rights reserved.\n",
        "#    BSD license.\n",
        "from itertools import combinations, chain\n",
        "import time\n",
        "import statistics\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.datasets import DBLP\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.nn import SAGEConv, Linear, HeteroConv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:08.524352Z",
          "iopub.status.busy": "2021-11-03T06:00:08.523745Z"
        },
        "id": "T651JmUB14xE",
        "outputId": "16d6d614-de15-4636-e853-71a60681ad71",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 154 ms, sys: 72.7 ms, total: 227 ms\n",
            "Wall time: 11.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# GPU\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu110.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu110.html\n",
        "# !pip install -q torch-geometric\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install -q torch-scatter\n",
        "    !pip install -q torch-sparse\n",
        "    !pip install -q torch-geometric\n",
        "# !pip install -q torch-scatter\n",
        "# !pip install -q torch-sparse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGf7GXUH147v",
        "outputId": "b7b2a784-9868-498b-d0c9-715628214f18",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch-geometric\n",
            "Version: 2.0.2\n",
            "Summary: Graph Neural Network Library for PyTorch\n",
            "Home-page: https://github.com/pyg-team/pytorch_geometric\n",
            "Author: Matthias Fey\n",
            "Author-email: matthias.fey@tu-dortmund.de\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: pandas, scipy, PyYAML, googledrivedownloader, rdflib, tqdm, requests, yacs, scikit-learn, jinja2, networkx, pyparsing, numpy\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show torch-geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev95GBQFMTyL",
        "outputId": "5381730e-e612-4c61-9ff1-adf31538e45e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 19.1 s, sys: 7.18 s, total: 26.3 s\n",
            "Wall time: 21.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Global Variables\n",
        "# data = None\n",
        "# dataset = None\n",
        "# train_loader = None\n",
        "# val_loader = None\n",
        "# ds_num_classes = None\n",
        "\n",
        "def load_dataset(ds_name, node_tp):\n",
        "    # global data\n",
        "    # global dataset\n",
        "    # global train_loader\n",
        "    # global val_loader\n",
        "    # global ds_num_classes\n",
        "    path = '../data/' # IN_COLAB == True:\n",
        "    if ds_name == 'DBLP':\n",
        "        if IN_COLAB == False:\n",
        "          path = '/mnt/c/temp/working/data/DBLP/'\n",
        "        dataset = DBLP(path)\n",
        "        data = dataset[0]\n",
        "        # We initialize conference node features with a single feature.\n",
        "        data['conference'].x = torch.ones(data['conference'].num_nodes, 1)\n",
        "        ds_num_classes = 4\n",
        "        train_input_nodes = (node_tp, data[node_tp].train_mask)\n",
        "    elif ds_name == 'OGB_MAG':\n",
        "        if IN_COLAB == False:\n",
        "          path = '/mnt/c/temp/working/data/'\n",
        "        transform = T.ToUndirected()  # Add reverse edge types.\n",
        "        dataset = OGB_MAG(path, preprocess='metapath2vec', transform=transform)\n",
        "        data = dataset[0]\n",
        "        ds_num_classes = dataset.num_classes\n",
        "        train_input_nodes = (node_tp, data[node_tp].test_mask) #train->test\n",
        "    else:\n",
        "        print('Unknown dataset!')\n",
        "\n",
        "    val_input_nodes = (node_tp, data[node_tp].val_mask)\n",
        "    kwargs = {'batch_size': 64, 'num_workers': 2, 'persistent_workers': True}\n",
        "\n",
        "    train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=False,\n",
        "                                  input_nodes=train_input_nodes, **kwargs)\n",
        "\n",
        "    val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                                input_nodes=val_input_nodes, **kwargs)\n",
        "    return data, ds_num_classes, train_loader, val_loader\n",
        "\n",
        "\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, r_list, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HeteroConv({\n",
        "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
        "                for edge_type in r_list\n",
        "            })\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, edge_index_dict)\n",
        "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
        "        return self.lin(x_dict[node_tp])\n",
        "\n",
        "# ds_name = 'DBLP'\n",
        "# node_tp = 'author'  # node to predict\n",
        "ds_name = 'OGB_MAG'\n",
        "node_tp = 'paper'  # node to predict\n",
        "data, ds_num_classes, train_loader, val_loader =  load_dataset(ds_name, node_tp)\n",
        "# ds_num_classes = dataset.num_classes\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = HeteroGNN(data.metadata()[1], hidden_channels=64, out_channels=ds_num_classes,\n",
        "                  num_layers=2)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_params():\n",
        "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
        "    # print(\"In init, train_loader:\", train_loader)\n",
        "    batch = next(iter(train_loader))\n",
        "    batch = batch.to(device)\n",
        "    model(batch.x_dict, batch.edge_index_dict)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    i = 0\n",
        "    total_examples = total_loss = 0\n",
        "    # for batch in tqdm(train_loader):\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        # if i<1:\n",
        "        #   print(batch)\n",
        "        # i += 1\n",
        "\n",
        "        batch_size = batch[node_tp].batch_size\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        loss = F.cross_entropy(out[:batch_size], batch[node_tp].y[:batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_examples = total_correct = 0\n",
        "    for batch in tqdm(loader):\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch[node_tp].batch_size\n",
        "\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        pred = out.argmax(dim=-1)\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_correct += int((pred[:batch_size] ==\n",
        "                             batch[node_tp].y[:batch_size]).sum())\n",
        "\n",
        "    return total_correct / total_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pvICBiScXDBx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZb2WibZXDBz",
        "outputId": "db6b7c29-cb74-4dcb-82bb-42bc29100f4e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_relations = data.metadata()[1]\n",
        "# get all combinations, we will use this as indices for the columns later\n",
        "indices = list(powerset(range(len(all_relations))))\n",
        "# remove the empty subset\n",
        "indices.pop(0)\n",
        "# indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHYfuNAoXDB1",
        "outputId": "90b0d23c-f402-4adc-908d-e46115f341c3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mpaper\u001b[0m={\n",
              "    x=[9173, 128],\n",
              "    y=[9173],\n",
              "    train_mask=[9173],\n",
              "    val_mask=[9173],\n",
              "    test_mask=[9173],\n",
              "    batch_size=64\n",
              "  },\n",
              "  \u001b[1mauthor\u001b[0m={ x=[2173, 128] },\n",
              "  \u001b[1minstitution\u001b[0m={ x=[217, 128] },\n",
              "  \u001b[1mfield_of_study\u001b[0m={ x=[1536, 128] },\n",
              "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
              "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 2600] },\n",
              "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 5215] },\n",
              "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 3840] },\n",
              "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 454] },\n",
              "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 1950] },\n",
              "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 5438] }\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZouIH8t2XDB4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# for idx in indices:\n",
        "#     r_idx = list(idx)\n",
        "#     r_list = [all_relations[x] for x in r_idx]\n",
        "#     for item in r_list:\n",
        "#         if 'author' in item:\n",
        "#             print('Hast')\n",
        "#     print(r_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68D9GdhxXDB6",
        "outputId": "d090e99b-869e-42a3-8097-46614ef75cd5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['paper', 'author', 'institution', 'field_of_study']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# indices[-1]\n",
        "data.node_types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MVocNzm3xE8o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PYTHONOPTIMIZE = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cWKANi4unByz"
      },
      "outputs": [],
      "source": [
        "def check_pair_nodes(ds_name, r_list, nodes):\n",
        "\n",
        "    pair_nodes_in_r_list = True\n",
        "\n",
        "    if ds_name == 'DBLP':\n",
        "        for i in range(len(nodes)):\n",
        "            for j in np.arange(i+1, len(nodes)):\n",
        "                if (nodes[i], 'to', nodes[j]) in r_list and (nodes[j], 'to', nodes[i]) not in r_list:\n",
        "                    pair_nodes_in_r_list = False\n",
        "                    break\n",
        "                if (nodes[j], 'to', nodes[i]) in r_list and (nodes[i], 'to', nodes[j]) not in r_list:\n",
        "                    pair_nodes_in_r_list = False\n",
        "                    break\n",
        "\n",
        "    if ds_name == 'OGB_MAG':\n",
        "        for tpl in r_list:\n",
        "         # ارتباط مقاله به مقاله برعکس نداره که لزومی به چک کردنش باشد\n",
        "            if tpl[0] == tpl[2]:  # paper to paper\n",
        "                continue\n",
        "            # ایجاد تاپل متناظر با هر ارتباط\n",
        "            paired_tpl = tuple(reversed(tpl))\n",
        "            rel = tpl[1]\n",
        "            if rel.startswith('rev_'):\n",
        "                rel = rel[4:]\n",
        "            else:\n",
        "                rel = \"rev_\" + rel\n",
        "            lst = list(paired_tpl)\n",
        "            lst[1] = rel\n",
        "            paired_tpl = tuple(lst)\n",
        "            # tpl , paired_tpl\n",
        "            if paired_tpl not in r_list:\n",
        "                pair_nodes_in_r_list = False\n",
        "                break\n",
        "\n",
        "    return pair_nodes_in_r_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tSrwvUfDqTH1",
        "outputId": "7a3d7408-893e-42d2-83e7-2985d5c3da0e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r_list [('author', 'writes', 'paper'), ('paper', 'rev_writes', 'author')]\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "Report = []\n",
        "VAL_ACC = []\n",
        "R_LIST = []\n",
        "RUN_TIME = []\n",
        "# with tqdm(total=len(indices)) as progress_bar:\n",
        "rel_no = 0\n",
        "\n",
        "# ds_name = 'DBLP'\n",
        "# node_tp = 'author'  # node to predict\n",
        "\n",
        "ds_name = 'OGB_MAG'\n",
        "node_tp = 'paper'  # node to predict\n",
        "\n",
        "for idx in indices:\n",
        "    # idx = indices[-3]\n",
        "    r_idx = list(idx)\n",
        "    r_list = [all_relations[x] for x in r_idx]\n",
        "\n",
        "# نویسنده حتما باید باشه، چون طبقه‌بندی بر اساس اون هست\n",
        "    node_tp_in_r_list = False\n",
        "    if ds_name == 'DBLP':\n",
        "        if ('author', 'to', 'paper') in r_list and ('paper', 'to', 'author') in r_list:\n",
        "            node_tp_in_r_list = True\n",
        "    if ds_name == 'OGB_MAG':\n",
        "        if ('author', 'writes', 'paper') in r_list and ('paper', 'rev_writes', 'author') in r_list:\n",
        "            node_tp_in_r_list = True\n",
        "\n",
        "    if not node_tp_in_r_list:\n",
        "        continue\n",
        "\n",
        "# لیست نودهای موجود در این انتخاب\n",
        "    nodes = []\n",
        "    for items in r_list:\n",
        "        if items[0] not in nodes:\n",
        "            nodes.append(items[0])\n",
        "        if items[-1] not in nodes:\n",
        "            nodes.append(items[-1])\n",
        "\n",
        "  # اگر یک ارتباط هست، برعکسش هم باید باشه.\n",
        "    pair_nodes_in_r_list = check_pair_nodes(ds_name, r_list, nodes)\n",
        "    if not pair_nodes_in_r_list:\n",
        "        continue\n",
        "\n",
        "    print('r_list', r_list)\n",
        "    val_ACC = []\n",
        "    run_Times = []\n",
        "    for run_no in range(3):\n",
        "        start_time = time.time()\n",
        "        data, ds_num_classes, train_loader, val_loader = load_dataset(\n",
        "            ds_name, node_tp)\n",
        "\n",
        "        model = HeteroGNN(r_list, hidden_channels=64, out_channels=ds_num_classes,\n",
        "                          num_layers=2)\n",
        "        model = model.to(device)\n",
        "\n",
        "        init_params()  # Initialize parameters.\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "        for epoch in range(1, 2):\n",
        "            loss = train()\n",
        "\n",
        "        val_acc = test(val_loader)\n",
        "        # print(f'idx: {idx}, Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_acc:.4f}')\n",
        "        val_ACC.append(val_acc)\n",
        "        run_Times.append(time.time() - start_time)\n",
        "    # print(np.mean(VAL_ACC))\n",
        "    print('run_Times before prun:', run_Times)\n",
        "    run_Times_x = [[x] for x in run_Times]\n",
        "    # Outlier detection\n",
        "    iso = IsolationForest(contamination=0.1)\n",
        "    yhat = iso.fit_predict(run_Times_x)\n",
        "    run_Times = [run_Times[i] for (i, val) in enumerate(yhat) if val == 1]\n",
        "    print('run_Times after prun:', run_Times)\n",
        "    R_LIST.append(r_list)\n",
        "    VAL_ACC.append(np.mean(val_ACC))\n",
        "    RUN_TIME.append(statistics.mean(run_Times))\n",
        "    ds_report = [ds_name, rel_no, np.mean(val_ACC), statistics.mean(run_Times)]\n",
        "    Report.append(ds_report)\n",
        "    rel_no += 1\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    Report, columns=['Dataset Name', 'Rel. No.', 'ACC', 'Run Time'])\n",
        "print(df)\n",
        "# for i in range(len(R_LIST)):\n",
        "#   print(R_LIST[i], VAL_ACC[i], RUN_TIME[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L36n75cbLTzd",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "output_type": "error",
          "traceback": [
            "Error: Session cannot generate requests",
            "at w.executeCodeCell (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
            "at w.execute (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
            "at w.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
            "at runMicrotasks (<anonymous>)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at async t.CellExecutionQueue.executeQueuedCells (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
            "at async t.CellExecutionQueue.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
          ]
        }
      ],
      "source": [
        "print(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gDy643EXDB-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# R_LIST, VAL_ACC, RUN_TIME\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhedfkxfHhNP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html\n",
        "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyHgsK7dMwLw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# train_loader = HGTLoader(\n",
        "#     data,\n",
        "#     # Sample 64 nodes per type and per iteration for 4 iterations\n",
        "#     # num_samples={key: [64] * 4 for key in data.node_types},\n",
        "#     num_samples={key: [16] * 2 for key in node_list},\n",
        "#     # Use a batch size of 128 for sampling training nodes of type paper\n",
        "#     batch_size=32,\n",
        "#     input_nodes=train_input_nodes\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "comb_hgcn_dblp_ogb.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "acb5fe38fbd28c402c703fdbe5b19100300a03e07d3a6753113d2269daa5b738"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
