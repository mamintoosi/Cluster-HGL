{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hetero-NeighborSampler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2JJQt0p13mS",
        "outputId": "a5077371-8178-47b3-c134-3e4017662f4d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 24 08:45:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T651JmUB14xE",
        "outputId": "a368504a-66b2-4a8e-843c-8a61e3813616"
      },
      "source": [
        "%%time\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-geometric\n",
        "# !pip install -q torch-scatter\n",
        "# !pip install -q torch-sparse "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.0 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 379 kB 39.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.5 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "CPU times: user 169 ms, sys: 45.1 ms, total: 214 ms\n",
            "Wall time: 15.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGf7GXUH147v",
        "outputId": "ce10685a-fb05-4bbd-9fe1-0c357443c7a9"
      },
      "source": [
        "!pip show torch"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 1.9.0+cu102\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: typing-extensions\n",
            "Required-by: torchvision, torchtext, fastai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdVIbJY2LGSl"
      },
      "source": [
        "from torch_geometric.nn import HGTConv, Linear\n",
        "\n",
        "class HGT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin_dict = torch.nn.ModuleDict()\n",
        "        for node_type in data.node_types:\n",
        "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
        "                           num_heads, group='sum')\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        x_dict = {key: lin(x).relu() for key, lin in self.lin_dict.items()}\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, edge_index_dict)\n",
        "        return self.lin(x_dict['author'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZjce5MFJfVC"
      },
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "transform = T.ToUndirected()  # Add reverse edge types.\n",
        "data = OGB_MAG(root='../data', preprocess='metapath2vec', transform=transform)[0]\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
        "    num_neighbors=[15] * 2,\n",
        "    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
        "    batch_size=256,\n",
        "    input_nodes=('paper', data['paper'].train_mask),\n",
        ")\n",
        "\n",
        "batch = next(iter(train_loader))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxnHDOZKKmA0",
        "outputId": "85547ade-f060-4673-d6ad-a4acf109a631"
      },
      "source": [
        "print(batch)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mpaper\u001b[0m={\n",
            "    x=[38573, 128],\n",
            "    y=[38573],\n",
            "    train_mask=[38573],\n",
            "    val_mask=[38573],\n",
            "    test_mask=[38573],\n",
            "    batch_size=256\n",
            "  },\n",
            "  \u001b[1mauthor\u001b[0m={ x=[8281, 128] },\n",
            "  \u001b[1minstitution\u001b[0m={ x=[513, 128] },\n",
            "  \u001b[1mfield_of_study\u001b[0m={ x=[4145, 128] },\n",
            "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
            "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 11210] },\n",
            "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 24359] },\n",
            "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 17944] },\n",
            "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 1652] },\n",
            "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 10579] },\n",
            "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 21393] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L36n75cbLTzd",
        "outputId": "73b1804c-a75a-4416-87ef-6a90b07c7fd7"
      },
      "source": [
        "data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mpaper\u001b[0m={\n",
              "    x=[736389, 128],\n",
              "    y=[736389],\n",
              "    train_mask=[736389],\n",
              "    val_mask=[736389],\n",
              "    test_mask=[736389]\n",
              "  },\n",
              "  \u001b[1mauthor\u001b[0m={ x=[1134649, 128] },\n",
              "  \u001b[1minstitution\u001b[0m={ x=[8740, 128] },\n",
              "  \u001b[1mfield_of_study\u001b[0m={ x=[59965, 128] },\n",
              "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
              "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
              "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 10792672] },\n",
              "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] },\n",
              "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 1043998] },\n",
              "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 7145660] },\n",
              "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 7505078] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxUbgWK1K12x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhedfkxfHhNP"
      },
      "source": [
        "# https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html\n",
        "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev95GBQFMTyL",
        "outputId": "d8a51c61-e2f4-481c-9f15-e171a77932c9"
      },
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.nn import ReLU\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.loader import NeighborLoader, HGTLoader\n",
        "from torch_geometric.nn import Sequential, SAGEConv, Linear, to_hetero\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--use_hgt_loader', action='store_true')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# path = osp.join(osp.dirname(osp.realpath(__file__)), '../data/OGB')\n",
        "path = '../data'\n",
        "transform = T.ToUndirected(merge=True)\n",
        "dataset = OGB_MAG(path, preprocess='metapath2vec', transform=transform)\n",
        "data = dataset[0]\n",
        "\n",
        "train_input_nodes = ('paper', data['paper'].train_mask)\n",
        "val_input_nodes = ('paper', data['paper'].val_mask)\n",
        "kwargs = {'batch_size': 256, 'num_workers': 2, 'persistent_workers': True}\n",
        "\n",
        "train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=True,\n",
        "                              input_nodes=train_input_nodes, **kwargs)\n",
        "val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                            input_nodes=val_input_nodes, **kwargs)\n",
        "# if not args.use_hgt_loader:\n",
        "#     train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=True,\n",
        "#                                   input_nodes=train_input_nodes, **kwargs)\n",
        "#     val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "#                                 input_nodes=val_input_nodes, **kwargs)\n",
        "# else:\n",
        "#     train_loader = HGTLoader(data, num_samples=[1024] * 4, shuffle=True,\n",
        "#                              input_nodes=train_input_nodes, **kwargs)\n",
        "#     val_loader = HGTLoader(data, num_samples=[1024] * 4,\n",
        "#                            input_nodes=val_input_nodes, **kwargs)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Sequential('x, edge_index', [\n",
        "    (SAGEConv((-1, -1), 64), 'x, edge_index -> x'),\n",
        "    ReLU(inplace=True),\n",
        "    (SAGEConv((-1, -1), 64), 'x, edge_index -> x'),\n",
        "    ReLU(inplace=True),\n",
        "    (Linear(-1, dataset.num_classes), 'x -> x'),\n",
        "])\n",
        "model = to_hetero(model, data.metadata(), aggr='sum').to(device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_params():\n",
        "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
        "    batch = next(iter(train_loader))\n",
        "    batch = batch.to(device)\n",
        "    model(batch.x_dict, batch.edge_index_dict)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_examples = total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch['paper'].batch_size\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)['paper'][:batch_size]\n",
        "        loss = F.cross_entropy(out, batch['paper'].y[:batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_examples = total_correct = 0\n",
        "    for batch in tqdm(loader):\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch['paper'].batch_size\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)['paper'][:batch_size]\n",
        "        pred = out.argmax(dim=-1)\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_correct += int((pred == batch['paper'].y[:batch_size]).sum())\n",
        "\n",
        "    return total_correct / total_examples\n",
        "\n",
        "\n",
        "init_params()  # Initialize parameters.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    loss = train()\n",
        "    val_acc = test(val_loader)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 2460/2460 [11:45<00:00,  3.49it/s]\n",
            "100%|██████████| 254/254 [01:13<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 2.4314, Val: 0.3972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 1441/2460 [06:31<04:00,  4.23it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyHgsK7dMwLw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}