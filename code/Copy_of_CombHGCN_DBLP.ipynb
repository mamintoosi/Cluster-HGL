{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y2JJQt0p13mS"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wp0E9mvTXDBl"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "#    Copyright (C) 2021-2029 by\n",
        "#    Mahmood Amintoosi <m.amintoosi@gmail.com>\n",
        "#    All rights reserved.\n",
        "#    BSD license.\n",
        "from itertools import combinations, chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T651JmUB14xE",
        "outputId": "6fbb86b9-9c93-46df-cdfd-e6f9f6e358a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 232 ms, sys: 156 ms, total: 388 ms\n",
            "Wall time: 9.22 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q torch-geometric\n",
        "# !pip install -q torch-scatter\n",
        "# !pip install -q torch-sparse "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HGf7GXUH147v"
      },
      "outputs": [],
      "source": [
        "# !pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ev95GBQFMTyL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import os.path as osp\n",
        "from tqdm import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import torch\n",
        "from torch.nn import ReLU\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "# from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.datasets import DBLP\n",
        "from torch_geometric.loader import NeighborLoader, HGTLoader\n",
        "from torch_geometric.nn import Sequential, SAGEConv, Linear, to_hetero, HeteroConv\n",
        "\n",
        "# path = '../data/DBLP/'\n",
        "path = '/mnt/c/temp/working/data/DBLP/'\n",
        "dataset = DBLP(path)\n",
        "data = dataset[0]\n",
        "\n",
        "# We initialize conference node features with a single feature.\n",
        "data['conference'].x = torch.ones(data['conference'].num_nodes, 1)\n",
        "\n",
        "train_input_nodes = ('author', data['author'].train_mask)\n",
        "val_input_nodes = ('author', data['author'].val_mask)\n",
        "kwargs = {'batch_size': 64, 'num_workers': 2, 'persistent_workers': True}\n",
        "\n",
        "train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=False,\n",
        "                              input_nodes=train_input_nodes, **kwargs)\n",
        "\n",
        "val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                            input_nodes=val_input_nodes, **kwargs)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# r_list is the list of relation which will be considered in network\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, r_list, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HeteroConv({\n",
        "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
        "                for edge_type in r_list\n",
        "                # metadata[1]#[:2] #انتخاب فقط دو رابطه‌ی اول\n",
        "            })\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, edge_index_dict)\n",
        "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
        "        return self.lin(x_dict['author'])\n",
        "\n",
        "\n",
        "model = HeteroGNN(data.metadata()[1], hidden_channels=64, out_channels=4,\n",
        "                  num_layers=2)\n",
        "model = model.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_params():\n",
        "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
        "    # print(\"In init, train_loader:\", train_loader)\n",
        "    batch = next(iter(train_loader))\n",
        "    batch = batch.to(device)\n",
        "    model(batch.x_dict, batch.edge_index_dict)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    i = 0\n",
        "    total_examples = total_loss = 0\n",
        "    # for batch in tqdm(train_loader):\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        # if i<1:\n",
        "        #   print(batch)\n",
        "        # i += 1\n",
        "\n",
        "        batch_size = batch['author'].batch_size\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        loss = F.cross_entropy(out[:batch_size], batch['author'].y[:batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_examples = total_correct = 0\n",
        "    for batch in tqdm(loader):\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch['author'].batch_size\n",
        "\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        pred = out.argmax(dim=-1)\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_correct += int((pred[:batch_size] == batch['author'].y[:batch_size]).sum())\n",
        "\n",
        "    return total_correct / total_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pvICBiScXDBx"
      },
      "outputs": [],
      "source": [
        "def powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZb2WibZXDBz",
        "outputId": "8991e928-e257-4509-8587-dd3caa47b71e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_relations = data.metadata()[1]\n",
        "# get all combinations, we will use this as indices for the columns later\n",
        "indices = list(powerset(range(len(all_relations))))\n",
        "# remove the empty subset\n",
        "indices.pop(0)\n",
        "# indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHYfuNAoXDB1",
        "outputId": "e8f42bcf-f0d8-4e3c-fe79-82a3ef49d630"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mauthor\u001b[0m={\n",
              "    x=[174, 334],\n",
              "    y=[174],\n",
              "    train_mask=[174],\n",
              "    val_mask=[174],\n",
              "    test_mask=[174],\n",
              "    batch_size=64\n",
              "  },\n",
              "  \u001b[1mpaper\u001b[0m={ x=[334, 4231] },\n",
              "  \u001b[1mterm\u001b[0m={ x=[930, 50] },\n",
              "  \u001b[1mconference\u001b[0m={\n",
              "    num_nodes=19,\n",
              "    x=[19, 1]\n",
              "  },\n",
              "  \u001b[1m(author, to, paper)\u001b[0m={ edge_index=[2, 521] },\n",
              "  \u001b[1m(paper, to, author)\u001b[0m={ edge_index=[2, 334] },\n",
              "  \u001b[1m(paper, to, term)\u001b[0m={ edge_index=[2, 0] },\n",
              "  \u001b[1m(paper, to, conference)\u001b[0m={ edge_index=[2, 0] },\n",
              "  \u001b[1m(term, to, paper)\u001b[0m={ edge_index=[2, 2026] },\n",
              "  \u001b[1m(conference, to, paper)\u001b[0m={ edge_index=[2, 334] }\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZouIH8t2XDB4"
      },
      "outputs": [],
      "source": [
        "# for idx in indices:       \n",
        "#     r_idx = list(idx)\n",
        "#     r_list = [all_relations[x] for x in r_idx]\n",
        "#     for item in r_list:\n",
        "#         if 'author' in item:\n",
        "#             print('Hast')\n",
        "#     print(r_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68D9GdhxXDB6",
        "outputId": "a1642a0d-110d-41e1-da8e-a8e4afa8d462"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['author', 'paper', 'term', 'conference']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# indices[-1]\n",
        "data.node_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSrwvUfDqTH1",
        "outputId": "2fb4b3d3-f92e-4036-d917-f303d94b9a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r_list [('author', 'to', 'paper'), ('paper', 'to', 'author')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "self._shutdown_workers()    \n",
            "self._shutdown_workers()  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():    \n",
            "if w.is_alive():  File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: AssertionError: can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "      File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "\n",
            "    AssertionErrorif w.is_alive():: \n",
            "can only test a child process\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>\n",
            "\n",
            "AssertionError: Traceback (most recent call last):\n",
            "can only test a child process\n",
            "  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fad76b5d8c0>  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():  File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "\n",
            "      File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "self._shutdown_workers()\n",
            "      File \"/home/mahmood/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    AssertionErrorif w.is_alive():: \n",
            "can only test a child process  File \"/home/mahmood/anaconda3/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "100%|██████████| 7/7 [00:00<00:00, 38.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "idx: (0, 1), Epoch: 20, Loss: 0.0000, Val: 0.7750\n",
            "r_list [('author', 'to', 'paper'), ('paper', 'to', 'author'), ('paper', 'to', 'term'), ('term', 'to', 'paper')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 43.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "idx: (0, 1, 2, 4), Epoch: 20, Loss: 0.0000, Val: 0.7675\n",
            "r_list [('author', 'to', 'paper'), ('paper', 'to', 'author'), ('paper', 'to', 'conference'), ('conference', 'to', 'paper')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 14.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "idx: (0, 1, 3, 5), Epoch: 20, Loss: 0.0000, Val: 0.7600\n",
            "r_list [('author', 'to', 'paper'), ('paper', 'to', 'author'), ('paper', 'to', 'term'), ('paper', 'to', 'conference'), ('term', 'to', 'paper'), ('conference', 'to', 'paper')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 19.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "idx: (0, 1, 2, 3, 4, 5), Epoch: 20, Loss: 0.0000, Val: 0.7800\n",
            "CPU times: user 2min 12s, sys: 50.5 s, total: 3min 3s\n",
            "Wall time: 7min 17s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# with tqdm(total=len(indices)) as progress_bar:\n",
        "for idx in indices:\n",
        "# idx = indices[-3]\n",
        "    r_idx = list(idx)\n",
        "    r_list = [all_relations[x] for x in r_idx]\n",
        "\n",
        "# نویسنده حتما باید باشه، چون طبقه‌بندی بر اسا اون هست\n",
        "    author_in_r_list = False\n",
        "    if ('author', 'to', 'paper') in r_list and ('paper', 'to', 'author') in r_list:\n",
        "        author_in_r_list = True\n",
        "    if not author_in_r_list:\n",
        "        continue\n",
        "\n",
        "    \n",
        "\n",
        "    # if ('term', 'to', 'paper') in r_list and ('paper', 'to', 'term') not in r_list:\n",
        "    #     author_in_r_list = True\n",
        "    # if not author_in_r_list:\n",
        "    #     continue\n",
        "            \n",
        "    nodes = []\n",
        "    for items in r_list:\n",
        "        for item in items:\n",
        "            if item not in nodes and item != 'to':\n",
        "                nodes.append(item)\n",
        "    #     # if 'author' in items:\n",
        "    #     #     author_in_r_list = True\n",
        "    #         # break\n",
        "    # print('Node_list', node_list)        \n",
        "\n",
        "  # اگر یک ارتباط هست، برعکسش هم باید باشه.\n",
        "    pair_nodes_in_r_list = True\n",
        "    # nodes = data.node_types\n",
        "    for i in range(len(nodes)):\n",
        "      for j in np.arange(i+1,len(nodes)):\n",
        "        if (nodes[i],'to',nodes[j]) in r_list and (nodes[j],'to',nodes[i]) not in r_list:\n",
        "          pair_nodes_in_r_list = False\n",
        "          break\n",
        "        if (nodes[j],'to',nodes[i]) in r_list and (nodes[i],'to',nodes[j]) not in r_list:\n",
        "          pair_nodes_in_r_list = False\n",
        "          break\n",
        "\n",
        "          \n",
        "  \n",
        "    if not pair_nodes_in_r_list:\n",
        "        continue\n",
        "\n",
        "    print('r_list', r_list)\n",
        "\n",
        "    model = HeteroGNN(r_list, hidden_channels=64, out_channels=4,\n",
        "                    num_layers=2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # train_loader = HGTLoader(\n",
        "    #     data,\n",
        "    #     # Sample 64 nodes per type and per iteration for 4 iterations\n",
        "    #     # num_samples={key: [64] * 4 for key in data.node_types},\n",
        "    #     num_samples={key: [16] * 2 for key in node_list},\n",
        "    #     # Use a batch size of 128 for sampling training nodes of type paper\n",
        "    #     batch_size=32,\n",
        "    #     input_nodes=train_input_nodes\n",
        "    # )\n",
        "\n",
        "    train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=True,\n",
        "                                input_nodes=train_input_nodes, **kwargs)\n",
        "    init_params()  # Initialize parameters.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(1, 21):\n",
        "        loss = train()\n",
        "        \n",
        "    val_acc = test(val_loader)\n",
        "    print(f'idx: {idx}, Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L36n75cbLTzd"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gDy643EXDB-"
      },
      "outputs": [],
      "source": [
        "sampled_hetero_data = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxUbgWK1K12x",
        "outputId": "9afd17d6-307e-4167-bbe9-1b8c05011ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1\n",
            "0 2\n",
            "0 3\n",
            "1 2\n",
            "1 3\n",
            "2 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nodes = data.node_types\n",
        "for i in range(len(nodes)):\n",
        "  for j in np.arange(i+1,len(nodes)):\n",
        "    print(i,j)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhedfkxfHhNP"
      },
      "outputs": [],
      "source": [
        "# https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html\n",
        "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyHgsK7dMwLw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of CombHGCN-DBLP.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "acb5fe38fbd28c402c703fdbe5b19100300a03e07d3a6753113d2269daa5b738"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
