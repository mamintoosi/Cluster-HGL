{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:07.800140Z",
          "iopub.status.busy": "2021-11-03T06:00:07.799891Z",
          "iopub.status.idle": "2021-11-03T06:00:08.509581Z",
          "shell.execute_reply": "2021-11-03T06:00:08.508770Z",
          "shell.execute_reply.started": "2021-11-03T06:00:07.800068Z"
        },
        "id": "Y2JJQt0p13mS",
        "outputId": "88220041-b347-40bb-a93e-eda50d5d526c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0mmf4TeY41d"
      },
      "source": [
        "مقایسه بین تعداد نورونهای لایه پنهان متفاوت در روابط مختلف\n",
        "مقایسه روابط مختلف که کدام روابط نتیجه بهتری دارند\n",
        "کدام زمان کمتری دارند\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:08.512072Z",
          "iopub.status.busy": "2021-11-03T06:00:08.511758Z",
          "iopub.status.idle": "2021-11-03T06:00:08.522343Z",
          "shell.execute_reply": "2021-11-03T06:00:08.521542Z",
          "shell.execute_reply.started": "2021-11-03T06:00:08.512037Z"
        },
        "id": "wp0E9mvTXDBl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "#    Copyright (C) 2021-2029 by\n",
        "#    Mahmood Amintoosi <m.amintoosi@gmail.com>\n",
        "#    All rights reserved.\n",
        "#    BSD license.\n",
        "from itertools import combinations, chain\n",
        "import time\n",
        "import statistics\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-03T06:00:08.524352Z",
          "iopub.status.busy": "2021-11-03T06:00:08.523745Z"
        },
        "id": "T651JmUB14xE",
        "outputId": "810157be-7a5e-439b-c5ec-c8380c835e8b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 43 kB 590 kB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 325 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 39.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "CPU times: user 5.68 s, sys: 876 ms, total: 6.55 s\n",
            "Wall time: 12min 37s\n"
          ]
        }
      ],
      "source": [
        "% % time\n",
        "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu110.html\n",
        "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu110.html\n",
        "!pip install - q torch-scatter\n",
        "!pip install - q torch-sparse\n",
        "!pip install - q torch-geometric\n",
        "# !pip install -q torch-scatter\n",
        "# !pip install -q torch-sparse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGf7GXUH147v",
        "outputId": "7d7d1b01-23ed-47ac-86f6-fa89c5dd7e58",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch-geometric\n",
            "Version: 2.0.1\n",
            "Summary: Graph Neural Network Library for PyTorch\n",
            "Home-page: https://github.com/pyg-team/pytorch_geometric\n",
            "Author: Matthias Fey\n",
            "Author-email: matthias.fey@tu-dortmund.de\n",
            "License: UNKNOWN\n",
            "Location: /home/mahmood/anaconda3/lib/python3.7/site-packages\n",
            "Requires: pyparsing, scipy, networkx, rdflib, tqdm, pandas, googledrivedownloader, PyYAML, numpy, jinja2, yacs, requests, scikit-learn\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show torch-geometric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev95GBQFMTyL",
        "outputId": "715f6d51-75a2-4f30-a130-f6c092c5085f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.datasets import DBLP\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.nn import SAGEConv, Linear, HeteroConv\n",
        "\n",
        "# Global Variables\n",
        "# data = None\n",
        "# dataset = None\n",
        "# train_loader = None\n",
        "# val_loader = None\n",
        "# ds_num_classes = None\n",
        "\n",
        "def load_dataset(ds_name, node_tp):\n",
        "    # global data\n",
        "    # global dataset\n",
        "    # global train_loader\n",
        "    # global val_loader\n",
        "    # global ds_num_classes\n",
        "    path = '../data/'\n",
        "    if ds_name == 'DBLP':\n",
        "        path = '/mnt/c/temp/working/data/DBLP/'\n",
        "        dataset = DBLP(path)\n",
        "        data = dataset[0]\n",
        "        # We initialize conference node features with a single feature.\n",
        "        data['conference'].x = torch.ones(data['conference'].num_nodes, 1)\n",
        "        ds_num_classes = 4\n",
        "    elif ds_name == 'OGB_MAG':\n",
        "        path = '/mnt/c/temp/working/data/'\n",
        "        transform = T.ToUndirected()  # Add reverse edge types.\n",
        "        dataset = OGB_MAG(path, preprocess='metapath2vec', transform=transform)\n",
        "        data = dataset[0]\n",
        "        ds_num_classes = dataset.num_classes\n",
        "    else:\n",
        "        print('Unknown dataset!')\n",
        "\n",
        "    train_input_nodes = (node_tp, data[node_tp].train_mask)\n",
        "    val_input_nodes = (node_tp, data[node_tp].val_mask)\n",
        "    kwargs = {'batch_size': 64, 'num_workers': 2, 'persistent_workers': True}\n",
        "\n",
        "    train_loader = NeighborLoader(data, num_neighbors=[10] * 2, shuffle=False,\n",
        "                                  input_nodes=train_input_nodes, **kwargs)\n",
        "\n",
        "    val_loader = NeighborLoader(data, num_neighbors=[10] * 2,\n",
        "                                input_nodes=val_input_nodes, **kwargs)\n",
        "    return data, ds_num_classes, train_loader, val_loader\n",
        "\n",
        "\n",
        "# ds_name = 'DBLP'\n",
        "# node_tp = 'author'  # node to predict\n",
        "ds_name = 'OGB_MAG'\n",
        "node_tp = 'paper'  # node to predict\n",
        "data, ds_num_classes, train_loader, val_loader =  load_dataset(ds_name, node_tp)\n",
        "# ds_num_classes = dataset.num_classes\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# r_list is the list of relation which will be considered in network\n",
        "\n",
        "\n",
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, r_list, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HeteroConv({\n",
        "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
        "                for edge_type in r_list\n",
        "            })\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, edge_index_dict)\n",
        "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
        "        return self.lin(x_dict[node_tp])\n",
        "\n",
        "\n",
        "model = HeteroGNN(data.metadata()[1], hidden_channels=64, out_channels=ds_num_classes,\n",
        "                  num_layers=2)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def init_params():\n",
        "    # Initialize lazy parameters via forwarding a single batch to the model:\n",
        "    # print(\"In init, train_loader:\", train_loader)\n",
        "    batch = next(iter(train_loader))\n",
        "    batch = batch.to(device)\n",
        "    model(batch.x_dict, batch.edge_index_dict)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    i = 0\n",
        "    total_examples = total_loss = 0\n",
        "    # for batch in tqdm(train_loader):\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "        # if i<1:\n",
        "        #   print(batch)\n",
        "        # i += 1\n",
        "\n",
        "        batch_size = batch[node_tp].batch_size\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        loss = F.cross_entropy(out[:batch_size], batch[node_tp].y[:batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_loss += float(loss) * batch_size\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_examples = total_correct = 0\n",
        "    for batch in tqdm(loader):\n",
        "        batch = batch.to(device)\n",
        "        batch_size = batch[node_tp].batch_size\n",
        "\n",
        "        out = model(batch.x_dict, batch.edge_index_dict)\n",
        "        pred = out.argmax(dim=-1)\n",
        "\n",
        "        total_examples += batch_size\n",
        "        total_correct += int((pred[:batch_size] ==\n",
        "                             batch[node_tp].y[:batch_size]).sum())\n",
        "\n",
        "    return total_correct / total_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pvICBiScXDBx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def powerset(iterable):\n",
        "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZb2WibZXDBz",
        "outputId": "6ad539d8-6f9e-4f9c-9813-7e91bbdddbef",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_relations = data.metadata()[1]\n",
        "# get all combinations, we will use this as indices for the columns later\n",
        "indices = list(powerset(range(len(all_relations))))\n",
        "# remove the empty subset\n",
        "indices.pop(0)\n",
        "# indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHYfuNAoXDB1",
        "outputId": "e0c02514-fce9-4fc0-aa0e-7021d0f9a7a7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1mpaper\u001b[0m={\n",
              "    x=[7489, 128],\n",
              "    y=[7489],\n",
              "    train_mask=[7489],\n",
              "    val_mask=[7489],\n",
              "    test_mask=[7489],\n",
              "    batch_size=64\n",
              "  },\n",
              "  \u001b[1mauthor\u001b[0m={ x=[1870, 128] },\n",
              "  \u001b[1minstitution\u001b[0m={ x=[162, 128] },\n",
              "  \u001b[1mfield_of_study\u001b[0m={ x=[1420, 128] },\n",
              "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
              "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 2344] },\n",
              "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 3580] },\n",
              "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 3810] },\n",
              "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 381] },\n",
              "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 2087] },\n",
              "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 4112] }\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZouIH8t2XDB4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# for idx in indices:\n",
        "#     r_idx = list(idx)\n",
        "#     r_list = [all_relations[x] for x in r_idx]\n",
        "#     for item in r_list:\n",
        "#         if 'author' in item:\n",
        "#             print('Hast')\n",
        "#     print(r_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68D9GdhxXDB6",
        "outputId": "cff3762a-5b30-493a-c40b-65893b40ce8a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['paper', 'author', 'institution', 'field_of_study']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# indices[-1]\n",
        "data.node_types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MVocNzm3xE8o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PYTHONOPTIMIZE = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_pair_nodes(ds_name, r_list, nodes):\n",
        "\n",
        "    pair_nodes_in_r_list = True\n",
        "\n",
        "    if ds_name == 'DBLP':\n",
        "        for i in range(len(nodes)):\n",
        "            for j in np.arange(i+1, len(nodes)):\n",
        "                if (nodes[i], 'to', nodes[j]) in r_list and (nodes[j], 'to', nodes[i]) not in r_list:\n",
        "                    pair_nodes_in_r_list = False\n",
        "                    break\n",
        "                if (nodes[j], 'to', nodes[i]) in r_list and (nodes[i], 'to', nodes[j]) not in r_list:\n",
        "                    pair_nodes_in_r_list = False\n",
        "                    break\n",
        "\n",
        "    if ds_name == 'OGB_MAG':\n",
        "        for tpl in r_list:\n",
        "         # ارتباط مقاله به مقاله برعکس نداره که لزومی به چک کردنش باشد\n",
        "            if tpl[0] == tpl[2]:  # paper to paper\n",
        "                continue\n",
        "            # ایجاد تاپل متناظر با هر ارتباط\n",
        "            paired_tpl = tuple(reversed(tpl))\n",
        "            rel = tpl[1]\n",
        "            if rel.startswith('rev_'):\n",
        "                rel = rel[4:]\n",
        "            else:\n",
        "                rel = \"rev_\" + rel\n",
        "            lst = list(paired_tpl)\n",
        "            lst[1] = rel\n",
        "            paired_tpl = tuple(lst)\n",
        "            # tpl , paired_tpl\n",
        "            if paired_tpl not in r_list:\n",
        "                pair_nodes_in_r_list = False\n",
        "                break\n",
        "\n",
        "    return pair_nodes_in_r_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSrwvUfDqTH1",
        "outputId": "eb05d931-52e3-46f8-a92c-cc577bccc2e2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "Report = []\n",
        "VAL_ACC = []\n",
        "R_LIST = []\n",
        "RUN_TIME = []\n",
        "# with tqdm(total=len(indices)) as progress_bar:\n",
        "rel_no = 0\n",
        "\n",
        "# ds_name = 'DBLP'\n",
        "# node_tp = 'author'  # node to predict\n",
        "\n",
        "ds_name = 'OGB_MAG'\n",
        "node_tp = 'paper'  # node to predict\n",
        "\n",
        "for idx in indices:\n",
        "    # idx = indices[-3]\n",
        "    r_idx = list(idx)\n",
        "    r_list = [all_relations[x] for x in r_idx]\n",
        "\n",
        "# نویسنده حتما باید باشه، چون طبقه‌بندی بر اساس اون هست\n",
        "    node_tp_in_r_list = False\n",
        "    if ds_name == 'DBLP':\n",
        "        if ('author', 'to', 'paper') in r_list and ('paper', 'to', 'author') in r_list:\n",
        "            node_tp_in_r_list = True\n",
        "    if ds_name == 'OGB_MAG':\n",
        "        if ('author', 'writes', 'paper') in r_list and ('paper', 'rev_writes', 'author') in r_list:\n",
        "            node_tp_in_r_list = True\n",
        "\n",
        "    if not node_tp_in_r_list:\n",
        "        continue\n",
        "\n",
        "# لیست نودهای موجود در این انتخاب\n",
        "    nodes = []\n",
        "    for items in r_list:\n",
        "        if items[0] not in nodes:\n",
        "            nodes.append(items[0])\n",
        "        if items[-1] not in nodes:\n",
        "            nodes.append(items[-1])\n",
        "\n",
        "  # اگر یک ارتباط هست، برعکسش هم باید باشه.\n",
        "    pair_nodes_in_r_list = check_pair_nodes(ds_name, r_list, nodes)\n",
        "    if not pair_nodes_in_r_list:\n",
        "        continue\n",
        "\n",
        "    val_ACC = []\n",
        "    run_Times = []\n",
        "    for run_no in range(3):\n",
        "        start_time = time.time()\n",
        "        data, ds_num_classes, train_loader, val_loader = load_dataset(\n",
        "            ds_name, node_tp)\n",
        "\n",
        "        model = HeteroGNN(r_list, hidden_channels=64, out_channels=ds_num_classes,\n",
        "                          num_layers=2)\n",
        "        model = model.to(device)\n",
        "\n",
        "        init_params()  # Initialize parameters.\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "        for epoch in range(1, 2):\n",
        "            loss = train()\n",
        "\n",
        "        val_acc = test(val_loader)\n",
        "        # print(f'idx: {idx}, Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_acc:.4f}')\n",
        "        val_ACC.append(val_acc)\n",
        "        run_Times.append(time.time() - start_time)\n",
        "    # print('r_list', r_list)\n",
        "    # print(np.mean(VAL_ACC))\n",
        "    print('run_Times before prun:', run_Times)\n",
        "    run_Times_x = [[x] for x in run_Times]\n",
        "    # Outlier detection\n",
        "    iso = IsolationForest(contamination=0.1)\n",
        "    yhat = iso.fit_predict(run_Times_x)\n",
        "    run_Times = [run_Times[i] for (i, val) in enumerate(yhat) if val == 1]\n",
        "    print('run_Times after prun:', run_Times)\n",
        "    R_LIST.append(r_list)\n",
        "    VAL_ACC.append(np.mean(val_ACC))\n",
        "    RUN_TIME.append(statistics.mean(run_Times))\n",
        "    ds_report = [ds_name, rel_no, np.mean(val_ACC), statistics.mean(run_Times)]\n",
        "    Report.append(ds_report)\n",
        "    rel_no += 1\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    Report, columns=['Dataset Name', 'Rel. No.', 'ACC', 'Run Time'])\n",
        "print(df)\n",
        "# for i in range(len(R_LIST)):\n",
        "#   print(R_LIST[i], VAL_ACC[i], RUN_TIME[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L36n75cbLTzd",
        "outputId": "aec482ce-bc0e-412f-f677-c3ea4346e281",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "output_type": "error",
          "traceback": [
            "Error: Session cannot generate requests",
            "at w.executeCodeCell (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
            "at w.execute (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
            "at w.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
            "at runMicrotasks (<anonymous>)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at async t.CellExecutionQueue.executeQueuedCells (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
            "at async t.CellExecutionQueue.start (/home/mahmood/.vscode-server/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
          ]
        }
      ],
      "source": [
        "print(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gDy643EXDB-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# R_LIST, VAL_ACC, RUN_TIME\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhedfkxfHhNP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html\n",
        "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/to_hetero_mag.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyHgsK7dMwLw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# train_loader = HGTLoader(\n",
        "#     data,\n",
        "#     # Sample 64 nodes per type and per iteration for 4 iterations\n",
        "#     # num_samples={key: [64] * 4 for key in data.node_types},\n",
        "#     num_samples={key: [16] * 2 for key in node_list},\n",
        "#     # Use a batch size of 128 for sampling training nodes of type paper\n",
        "#     batch_size=32,\n",
        "#     input_nodes=train_input_nodes\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "com-bhgcn-dblp-ogb.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "acb5fe38fbd28c402c703fdbe5b19100300a03e07d3a6753113d2269daa5b738"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
